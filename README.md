# Seq2seq_attn
## Use the Seq2Seq method to implement machine translation and introduce Attention mechanism to improve the results
- Using ** Pytroch** to implement NLP task in mechain translation
- `NLP_translation.py`: implement model training and testing 
-  `Attention.py`: Using Seq2Seq with attenion
-  `PlainSeq2Seq` : Using Seq2Seq without attention

We also store the model and the DataSets in the directory `./data/nmt`
